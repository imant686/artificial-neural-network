{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c3c1e44-72f7-4641-8c24-f68f85ed56df",
   "metadata": {
    "id": "de3925d8-7b06-4660-a261-6c6122725df7"
   },
   "source": [
    "<h1>F20BC Coursework</h1>\n",
    "<p style=\"font-size:15px;\">This notebook implements and analyses the Biologically-Inspired Computation coursework, focusing on Artificial Neural Networks (ANNs) and Particle Swarm Optimization (PSO). It includes a multi-layer ANN architecture trained using PSO to solve a regression task predicting concrete compressive strength. Additionally, it explores the impact of hyperparameters on model performance through systematic experiments.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebafff1-e6fe-4c34-a1d1-773ddaac79d0",
   "metadata": {},
   "source": [
    "**<p style=\"font-size:18px;\">Data Preparation</p>** \n",
    "This contains all the data preprocessing and cleaning</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "id": "809b53d2-be68-4d76-b10a-080316806117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/imanteh/f20bc/F21BC/Notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "id": "3a814445-6960-4c14-9e10-edfba438d3a8",
   "metadata": {
    "id": "3a814445-6960-4c14-9e10-edfba438d3a8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "id": "f86173b9-c298-4a34-98c2-74a443f8e0a0",
   "metadata": {
    "id": "f86173b9-c298-4a34-98c2-74a443f8e0a0"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Dataset/concrete_data.csv\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "id": "5650ca39-2c52-45cf-800e-778720fa11d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "5650ca39-2c52-45cf-800e-778720fa11d8",
    "outputId": "fd7be3b5-3708-40c1-b7be-01f4a9dc68c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>blast_furnace_slag</th>\n",
       "      <th>fly_ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarse_aggregate</th>\n",
       "      <th>fine_aggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>concrete_compressive_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   coarse_aggregate  fine_aggregate   age  concrete_compressive_strength  \n",
       "0            1040.0            676.0   28                          79.99  \n",
       "1            1055.0            676.0   28                          61.89  \n",
       "2             932.0            594.0  270                          40.27  \n",
       "3             932.0            594.0  365                          41.05  \n",
       "4             978.4            825.5  360                          44.30  "
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "id": "033eda81-0b1f-47ab-aee0-fe85ec55ba85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "033eda81-0b1f-47ab-aee0-fe85ec55ba85",
    "outputId": "d40479cf-4067-4002-e741-bc60e7356f19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the dimensionality of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "cca774ba-5993-44d4-b484-6c5d2528a8bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "cca774ba-5993-44d4-b484-6c5d2528a8bd",
    "outputId": "1443dfd3-70e2-4044-b104-72aff9de75ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cement                           0\n",
       "blast_furnace_slag               0\n",
       "fly_ash                          0\n",
       "water                            0\n",
       "superplasticizer                 0\n",
       "coarse_aggregate                 0\n",
       "fine_aggregate                   0\n",
       "age                              0\n",
       "concrete_compressive_strength    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace = True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "id": "08f2c1bb-6ec4-4001-93cb-10c37d52d5d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08f2c1bb-6ec4-4001-93cb-10c37d52d5d3",
    "outputId": "6ad84cb3-0ed9-4a88-f267-3a9055a0cf50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows: 25\n"
     ]
    }
   ],
   "source": [
    "print(f'Duplicate rows: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "2c15b7ff-dfa1-4597-a5b8-d6ebd235be83",
   "metadata": {
    "id": "2c15b7ff-dfa1-4597-a5b8-d6ebd235be83"
   },
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c161d9-1652-478f-b10f-0d712bcad8cb",
   "metadata": {
    "id": "30f48e29-7d92-4504-b040-9b3f0b83ed87"
   },
   "source": [
    "**<p style=\"font-size:18px;\">Scaling and Encoding</p>** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "id": "aad8f012-5e57-418e-ae6e-a48e722ad63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  \\\n",
      "0   540.0                 0.0      0.0  162.0               2.5   \n",
      "1   540.0                 0.0      0.0  162.0               2.5   \n",
      "2   332.5               142.5      0.0  228.0               0.0   \n",
      "3   332.5               142.5      0.0  228.0               0.0   \n",
      "4   198.6               132.4      0.0  192.0               0.0   \n",
      "\n",
      "   coarse_aggregate  fine_aggregate   age  concrete_compressive_strength  \n",
      "0            1040.0            676.0   28                          79.99  \n",
      "1            1055.0            676.0   28                          61.89  \n",
      "2             932.0            594.0  270                          40.27  \n",
      "3             932.0            594.0  365                          41.05  \n",
      "4             978.4            825.5  360                          44.30  \n",
      "Index(['cement', 'blast_furnace_slag', 'fly_ash', 'water', 'superplasticizer',\n",
      "       'coarse_aggregate', 'fine_aggregate ', 'age',\n",
      "       'concrete_compressive_strength'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "id": "7d2a0134-ad67-4f9a-b445-736cfacd5100",
   "metadata": {
    "id": "7d2a0134-ad67-4f9a-b445-736cfacd5100"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:, :-1] # All columns except the last\n",
    "y = df.iloc[:, -1] # The last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "7f4e3c7d-d340-4ef3-a826-b2ead546ddeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1005, 8)\n",
      "(1005,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "b8919944-d878-4fed-afee-dbe16561684f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  \\\n",
      "0   540.0                 0.0      0.0  162.0               2.5   \n",
      "1   540.0                 0.0      0.0  162.0               2.5   \n",
      "2   332.5               142.5      0.0  228.0               0.0   \n",
      "3   332.5               142.5      0.0  228.0               0.0   \n",
      "4   198.6               132.4      0.0  192.0               0.0   \n",
      "\n",
      "   coarse_aggregate  fine_aggregate   age  \n",
      "0            1040.0            676.0   28  \n",
      "1            1055.0            676.0   28  \n",
      "2             932.0            594.0  270  \n",
      "3             932.0            594.0  365  \n",
      "4             978.4            825.5  360  \n"
     ]
    }
   ],
   "source": [
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "id": "704c9cfa-9b0f-4ee7-9351-3a75a79c2a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "c9590511-f8bd-451b-98e2-0e3d519bb67b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9590511-f8bd-451b-98e2-0e3d519bb67b",
    "outputId": "30d15b92-744a-457c-fb6d-f5e987d630ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of scaled training data:\n",
      "[[-0.7036142   0.7362629  -0.8810702   0.1799759  -1.0226942   1.32341753\n",
      "  -0.17765612 -0.62455318]\n",
      " [-0.83112259 -0.84582676  1.04788182 -0.72981642  0.63596651  1.35948653\n",
      "   0.32102131  0.88513966]\n",
      " [ 0.43140366  1.06620495 -0.8810702   0.38479825 -0.18498677 -1.33280675\n",
      "   0.00745899 -0.28365479]\n",
      " [-1.05233032  0.66864226  1.10026551 -0.30588178  0.28412939  0.42298068\n",
      "  -0.33758549 -0.51092038]\n",
      " [-1.17404287 -0.84582676  1.31904441  0.5419875   0.50193332 -1.24005789\n",
      "   1.18741037 -0.28365479]]\n"
     ]
    }
   ],
   "source": [
    "print(\"First 5 rows of scaled training data:\")\n",
    "print(X_train_scaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afa0bd9-28a9-45cc-9ba4-ad67062e2d75",
   "metadata": {
    "id": "78d90124-ed32-4fe9-a9e9-1be683f411d1"
   },
   "source": [
    "**<p style=\"font-size:18px;\">Artificial Neural Network (ANN)</p>**\n",
    "Below are the implementations of the ANN to train and predict concrete compressive strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "f36052af-8785-4f80-a652-a174b844c476",
   "metadata": {
    "id": "f36052af-8785-4f80-a652-a174b844c476"
   },
   "outputs": [],
   "source": [
    "class activationFunction:\n",
    "    def logisticFunction(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def reluFunction(x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def hyperbolicFunction(x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def leakyReLU(x, alpha=0.01):\n",
    "        return np.maximum(x, alpha * x)\n",
    "\n",
    "    def linearFunction(x):  # Identity function for regression output\n",
    "        return x\n",
    "    \n",
    "    # def elu(x, alpha=1.0):\n",
    "    #     return np.where(x > 0, x, alpha * (np.exp(x) - 1))\n",
    "\n",
    "class ArtificialNeuralNetwork:\n",
    "    def __init__(self, layerSize, activationFunction):\n",
    "        self.layerSize = layerSize\n",
    "        self.activationFunction = activationFunction\n",
    "        self.weights = [np.random.randn(layer_sizes[i], layer_sizes[i + 1]) * np.sqrt(2 / layer_sizes[i]) for i in range(len(layer_sizes) - 1)]\n",
    "        self.biases = [np.random.randn(1, layer_sizes[i + 1]) for i in range(len(layer_sizes) - 1)]\n",
    "\n",
    "    def forwardPropagation(self, x):\n",
    "        output = x\n",
    "        for i in range(len(self.weights)):\n",
    "            matrix_total = np.dot(output, self.weights[i]) + self.biases[i]\n",
    "            output = self.activationFunction[i](matrix_total)  \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea27674-968b-40b5-8b31-c4de3365a346",
   "metadata": {
    "id": "1ed5052f-91c5-4274-befd-9730ed83beb7"
   },
   "source": [
    "Layer size is structure to be 8,16,8,1 because \n",
    "- 8 input layers\n",
    "- 16 neurons in first hidden layer\n",
    "- 8 for the second hidden layer\n",
    "- 1 for the output layer<p>\n",
    "This is to check the predicted values generated after forward propagation from the ANN.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "8c52e988-67b2-445f-ba2a-1b11eabc73d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c52e988-67b2-445f-ba2a-1b11eabc73d8",
    "outputId": "8d0ca147-206a-48fa-ccf8-a9b7b0eac212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Output (Sample Predictions): [[ 0.10046464]\n",
      " [-0.09149112]\n",
      " [-0.25368316]\n",
      " [-0.15078599]\n",
      " [-0.24842705]\n",
      " [-0.30474659]\n",
      " [-0.12645748]\n",
      " [-0.32745264]]\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [8, 16, 8, 1]\n",
    "\n",
    "activation_functions = [\n",
    "    activationFunction.logisticFunction,\n",
    "    activationFunction.reluFunction,\n",
    "    activationFunction.linearFunction,\n",
    "]\n",
    "ann = ArtificialNeuralNetwork(layer_sizes, activation_functions)\n",
    "\n",
    "x_example = np.random.rand(8, 8)  #8 samples, 8 features\n",
    "output = ann.forwardPropagation(x_example)\n",
    "print(\"ANN Output (Sample Predictions):\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d093ea-6808-4968-8508-d6f304cf2453",
   "metadata": {
    "id": "78632050-f421-43b0-ab60-642af572e692"
   },
   "source": [
    "**<p style=\"font-size:18px;\">Loss Function</p>**\n",
    "Since the problem domian is regression, MSE is utilised as the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "37370e3e-512a-42a9-a622-35d32b96af49",
   "metadata": {
    "id": "37370e3e-512a-42a9-a622-35d32b96af49"
   },
   "outputs": [],
   "source": [
    "class lossFunction:\n",
    "    def evaluate(self,y_pred,y_train):\n",
    "        self.y_pred=y_pred\n",
    "        self.y_train=y_train\n",
    "class MeanSquaredError(lossFunction):\n",
    "    def evaluate(self, y_pred, y_train):\n",
    "        return np.mean((y_pred - y_train) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "465dcf79-542a-4fa4-b5de-a4a1da002e8e",
   "metadata": {
    "id": "465dcf79-542a-4fa4-b5de-a4a1da002e8e",
    "outputId": "e4834fcc-a4d2-4aa2-b316-c4e5ccfbcc94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred shape: (703, 1)\n",
      "y_train shape: (703, 1)\n",
      "Loss: 1482.7793846307336\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.to_numpy().reshape(-1, 1)\n",
    "y_pred = ann.forwardPropagation(X_train_scaled) # Forward propagating  through the ANN\n",
    "# checking y_pred and y_train has the correct shape\n",
    "print(\"y_pred shape:\", y_pred.shape) \n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "# use to calculate the loss function\n",
    "loss_function=MeanSquaredError()\n",
    "loss=loss_function.evaluate(y_pred, y_train)\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7df601-b058-4105-bdd4-8ddd878a28fe",
   "metadata": {
    "id": "75222630-f415-4b05-bdf5-778ea94c3c0d"
   },
   "source": [
    "**<p style=\"font-size:18px;\">Implement PSO Algorithm</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "9917bcd6-8081-4101-9a56-67827043922b",
   "metadata": {
    "id": "9917bcd6-8081-4101-9a56-67827043922b"
   },
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self,vectorSize):\n",
    "            self.particlePosition=np.random.rand(vectorSize)\n",
    "            self.particleVelocity=np.random.rand(vectorSize)\n",
    "            self.bestPosition=np.copy(self.particlePosition)\n",
    "            self.informants=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "ff9b7e2d-aa7c-410a-a632-6054362aba9e",
   "metadata": {
    "id": "ff9b7e2d-aa7c-410a-a632-6054362aba9e"
   },
   "outputs": [],
   "source": [
    "def particleToAnn(particle, annLayers, activationFunctions):\n",
    "    neuralNetwork = ArtificialNeuralNetwork(layerSize=annLayers, activationFunction=activationFunctions)\n",
    "    weightBiasIndexCount = 0\n",
    "    for i in range(len(annLayers) - 1):\n",
    "        prevValue = annLayers[i]\n",
    "        nextValue = annLayers[i + 1]\n",
    "        weightRange = prevValue * nextValue\n",
    "        \n",
    "        weight = particle.particlePosition[weightBiasIndexCount:weightBiasIndexCount + weightRange].reshape((prevValue, nextValue))\n",
    "        weightBiasIndexCount += weightRange\n",
    "        \n",
    "        biases = particle.particlePosition[weightBiasIndexCount:weightBiasIndexCount + nextValue].reshape((1, nextValue))\n",
    "        weightBiasIndexCount += nextValue\n",
    "        \n",
    "        # activation = activationFunctions[i]\n",
    "        neuralNetwork.weights[i] = weight\n",
    "        neuralNetwork.biases[i] = biases\n",
    "    return neuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "q8TWIiVxbKSz",
   "metadata": {
    "id": "q8TWIiVxbKSz"
   },
   "outputs": [],
   "source": [
    "def assessFitness(particle, dataset, annLayers, activationFunctions, loss_function):\n",
    "    x, y = dataset\n",
    "    ann = particleToAnn(particle, annLayers, activationFunctions)\n",
    "    predictions = ann.forwardPropagation(x) \n",
    "    loss = loss_function.evaluate(predictions, y.reshape(-1, 1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "hg18WNeDa2Gp",
   "metadata": {
    "id": "hg18WNeDa2Gp"
   },
   "outputs": [],
   "source": [
    "class ParticleSwarmOptimisation:\n",
    "    def __init__(self, swarmSize, alpha, beta, delta, omega, jumpSize, informantCount, vectorSize):\n",
    "        self.swarmSize = swarmSize\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.delta = delta\n",
    "        self.omega = omega\n",
    "        self.jumpSize = jumpSize\n",
    "        self.informantCount = informantCount\n",
    "        self.vectorSize = vectorSize\n",
    "        self.global_best = None\n",
    "        self.global_best_fitness = float('inf')\n",
    "\n",
    "    def initInformants(self, informantCount, particleArray):\n",
    "        for p in particleArray:\n",
    "            potentialInformants = [potInf for potInf in particleArray if potInf != p]\n",
    "            p.informants = [random.choice(potentialInformants) for _ in range(informantCount)]\n",
    "\n",
    "    def get_best_informant(self, particle, dataset, annLayers, activationFunctions, loss_function):\n",
    "        bestInf = None\n",
    "        bestFitnessInf = float('-inf')\n",
    "        for i in particle.informants:\n",
    "            fitness = assessFitness(i, dataset, annLayers, activationFunctions, loss_function)\n",
    "            if fitness > bestFitnessInf:\n",
    "                bestFitnessInf = fitness\n",
    "                bestInf = i\n",
    "        return bestInf.particlePosition\n",
    "\n",
    "    def psoOptimisation(self, swarmSize, alpha, beta, gamma, jumpSize, informantCount, vectorSize,\n",
    "                        dataset, annLayers, activationFunctions, loss_function, max_iterations=100):\n",
    "        \n",
    "        particleArray = [Particle(vectorSize) for _ in range(swarmSize)]\n",
    "        self.initInformants(informantCount, particleArray)\n",
    "\n",
    "        best = None\n",
    "        iteration = 0\n",
    "\n",
    "        while iteration < max_iterations:\n",
    "            # update global best\n",
    "            for p in particleArray:\n",
    "                particleFitness = assessFitness(p, dataset, annLayers, activationFunctions, loss_function)\n",
    "                if best is None or particleFitness < assessFitness(best, dataset, annLayers, activationFunctions, loss_function):\n",
    "                    best = p\n",
    "\n",
    "            for p in particleArray:\n",
    "                previousBest = p.bestPosition\n",
    "                informantsBest = self.get_best_informant(p, dataset, annLayers, activationFunctions, loss_function)\n",
    "                allBest = best.bestPosition\n",
    "\n",
    "                b = np.random.uniform(0.0, beta)\n",
    "                c = np.random.uniform(0.0, gamma)\n",
    "                d = np.random.uniform(0.0, delta)\n",
    "\n",
    "                updatedVelocity = (\n",
    "                    alpha * p.particleVelocity +\n",
    "                    b * (previousBest - p.particlePosition) +\n",
    "                    c * (informantsBest - p.particlePosition) +\n",
    "                    d * (allBest - p.particlePosition)\n",
    "                )\n",
    "\n",
    "                p.particleVelocity = updatedVelocity\n",
    "                p.particlePosition += jumpSize * updatedVelocity\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "        return best.particlePosition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab11ff8-495b-42ee-80f3-84fcfd6e4707",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\">Test out PSO Functionality</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721c52e7-3b0c-4c31-ac90-72e95d9dfb67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "7142ac47-5039-45b7-9b10-452967e23575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimised ANN Parameters: [0.60170174 0.65474355 0.09944419 0.43370716 0.80973973 0.4234242\n",
      " 0.80529996 0.53757763 0.05815643 0.65684594 0.66052799 0.47272844\n",
      " 0.77012653 0.48983237 0.54726868 0.63873103 0.68384823 0.81049954\n",
      " 0.38808024 0.23737868 0.64998342 0.63029443 0.80265387 0.80566356\n",
      " 0.69747291 0.65095672 0.15906389 0.68932229 0.64114412 0.15112518\n",
      " 0.49159705 0.39185045 0.14876266 0.14046641 0.68610965 0.23769889\n",
      " 0.78491811 0.84934511 0.8644671  0.2345328  0.65203148 0.85262414\n",
      " 0.60370043 0.02030405 0.17173757 0.39808731 0.4156856  0.18377015\n",
      " 0.63593823 0.61704426 0.66324339 0.34667356 0.52289541 0.6256944\n",
      " 0.36508618 0.21276897 0.66403357 0.15168743 0.20804113 0.8054793\n",
      " 0.59509237 0.05191308 0.96517298 0.36620648 0.22479874 0.93183923\n",
      " 0.78024274 0.83390452 0.27690543 0.18922815 0.55063319 0.60915932\n",
      " 0.62145828 0.50211983 0.39841566 0.53866401 0.41433925 0.35834503\n",
      " 0.84687278 0.42641011 0.58312657 0.27953772 0.27798252 0.5189895\n",
      " 0.71551442 0.12459391 0.41360984 0.66532701 0.50753551 0.52680661\n",
      " 0.13660684 0.15486479 0.70881133 0.39837357 0.0592707  0.37114471\n",
      " 0.70942967 0.79844579 0.66377953 0.90737199 0.43243806 0.90530911\n",
      " 0.70035403 0.1238405  0.36026384 0.35408152 0.44866039 0.35737482\n",
      " 0.69586201 0.91303889 0.23131815 0.12494333 0.15188809 0.50345139\n",
      " 0.49278278 0.33527131 0.26698077 0.6928171  0.17328031 0.17088693\n",
      " 0.82133226 0.58366027 0.50611211 0.21299896 0.57198882 0.70708303\n",
      " 0.63704799 0.50981269 0.51790819 0.64420475 0.36942767 0.27644034\n",
      " 0.26841172 0.55411118 0.16066642 0.32716531 0.61087635 0.23179579\n",
      " 0.26236952 0.22844152 0.58389575 0.13008093 0.57027799 0.84455651\n",
      " 0.87143201 0.78622253 0.86173932 0.70689379 0.09017153 0.11863485\n",
      " 0.74334655 0.76804247 0.5628831  0.44952329 0.84963182 0.79021874\n",
      " 0.26933527 0.38997043 0.15598946 0.64487888 0.48231693 0.0806388\n",
      " 0.21227698 0.53962346 0.68483841 0.8136621  0.63228589 0.17244056\n",
      " 0.77717424 0.5719305  0.19517318 0.21745826 0.60459955 0.51739677\n",
      " 0.65637251 0.19673713 0.66349345 0.71446085 0.25151533 0.74743165\n",
      " 0.39132109 0.23478236 0.46913689 0.22032654 0.78289945 0.33135537\n",
      " 0.20306869 0.80564158 0.25393419 0.75514424 0.56852613 0.48840724\n",
      " 0.61734169 0.66657132 0.41532813 0.75199759 0.50877824 0.5755729\n",
      " 0.2883863  0.79179778 0.30813163 0.58414942 0.16658935 0.58263763\n",
      " 0.8552385  0.25437109 0.48881632 0.33556432 0.8200143  0.76885418\n",
      " 0.60416803 0.29709996 0.40758533 0.17229814 0.79801006 0.4984641\n",
      " 0.69998803 0.58724955 0.14374478 0.56821853 0.76255872 0.7891205\n",
      " 0.6079366  0.61985807 0.33606811 0.70774588 0.37008113 0.24822092\n",
      " 0.67909972 0.6644444  0.14098861 0.55185215 0.85946549 0.7917736\n",
      " 0.62410738 0.19713376 0.89372906 0.56309039 0.40600511 0.67359034\n",
      " 0.60236646 0.56781326 0.47280875 0.79402371 0.19884828 0.86181062\n",
      " 0.87222866 0.60423643 0.3602329  0.69540294 0.39538431 0.68853496\n",
      " 0.41853626 0.60496116 0.75185588 0.77333411 0.30647092 0.47723959\n",
      " 0.70144409 0.43634192 0.19221884 0.49514097 0.52087888 0.87614874\n",
      " 0.59836128 0.58607596 0.1481028  0.19496686 0.1468539  0.67318362\n",
      " 0.31961068 0.18886087 0.37312036 0.96931326 0.7385715  0.7731409\n",
      " 0.65229431 0.65756009 0.25300524 0.42371694 0.52923303 0.55865963\n",
      " 0.85143741 0.55338914 0.06404849 0.37655015 0.79826326 0.56267359\n",
      " 0.26460042]\n"
     ]
    }
   ],
   "source": [
    "# Code to test out PSO functionality\n",
    "X_train_scaled = np.random.rand(100, 8)  # Simulated scaled training features (100 samples, 8 features)\n",
    "y_train = np.random.rand(100, 1)  # Simulated training labels (100 samples, 1 output)\n",
    "\n",
    "# define hyperparameters for PSO \n",
    "swarmSize = 10\n",
    "alpha = 0.5  # inertia weight\n",
    "beta = 0.5   # cognitive parameter\n",
    "delta = 0.5  # social parameter\n",
    "jumpSize = 0.5\n",
    "informantCount = 3\n",
    "vectorSize = sum([(annLayers[i] * annLayers[i + 1]) + annLayers[i + 1] for i in range(len(annLayers) - 1)])  # Total weights + biases\n",
    "max_iterations = 50\n",
    "\n",
    "# initialize the PSO optimiser\n",
    "pso = ParticleSwarmOptimisation(\n",
    "    swarmSize = swarmSize,\n",
    "    alpha = alpha,\n",
    "    beta = beta,\n",
    "    delta = delta,\n",
    "    omega = omega,\n",
    "    jumpSize = jumpSize,\n",
    "    informantCount = informantCount,\n",
    "    vectorSize = vectorSize\n",
    ")\n",
    "\n",
    "# run it into the psoOptimisation\n",
    "best_parameters = pso.psoOptimisation(\n",
    "    swarmSize = swarmSize,\n",
    "    alpha = alpha,\n",
    "    beta = beta,\n",
    "    gamma = delta,  # Using delta as gamma as per your code\n",
    "    jumpSize = jumpSize,\n",
    "    informantCount = informantCount,\n",
    "    vectorSize = vectorSize,\n",
    "    \n",
    "    dataset = (X_train_scaled, y_train),\n",
    "    annLayers = annLayers,\n",
    "    activationFunctions = activationFunctions,\n",
    "    loss_function= MeanSquaredError(),\n",
    "    max_iterations = max_iterations\n",
    ")\n",
    "print(\"Optimised ANN Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d10176-98cc-4710-a683-f0a49d06430c",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\">Get Fitness Value</p>\n",
    "The final fitness represents the performance of the ANN after its weights and biases have been optimized by the PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "eda889e9-90ee-433d-a42f-f7c40e047b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness Value: 0.32897681927214445\n"
     ]
    }
   ],
   "source": [
    "# create a dummy particle and assign the optimized parameters\n",
    "optimised_particle = Particle(vectorSize)\n",
    "optimised_particle.particlePosition = best_parameters\n",
    "\n",
    "# convert the optimized particle position back to ANN weights and biases\n",
    "optimised_ann = particleToAnn(\n",
    "    optimised_particle, \n",
    "    annLayers,\n",
    "    activationFunctions\n",
    ")\n",
    "\n",
    "# run through ANN with the optimised parameters\n",
    "fitness_value = assessFitness(\n",
    "    optimised_particle,  # pass the optimised particle for fitness evaluation\n",
    "    dataset = (X_train_scaled, y_train),\n",
    "    annLayers = annLayers,\n",
    "    activationFunctions = activationFunctions,\n",
    "    loss_function = MeanSquaredError()\n",
    ")\n",
    "print(\"Fitness Value:\", fitness_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22fb274-eccd-464b-b0d0-eaa166c3c264",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\">Training the ANN</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "9bc8ad1a-430d-4e25-90c6-62c7eb4863ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.32897681927214445\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = optimized_ann.forwardPropagation(X_train_scaled)  # predictions for training data\n",
    "\n",
    "# calculate training loss (Mean Squared Error)\n",
    "loss_function = MeanSquaredError()  \n",
    "training_loss = loss_function.evaluate(y_train_pred, y_train)  # Evaluate MSE loss on training set\n",
    "\n",
    "print(f\"Training Loss: {training_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae53eaa-9653-4c9f-82f1-a48af3361e6b",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;\">Testing the model on the test set</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "62bcc0f9-5453-424e-960f-350ed3c320e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test_pred shape: (302, 1)\n",
      "y_test shape: (302,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_test_pred shape: {y_test_pred.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "a61bff07-7200-4eff-9f75-f9dc87b6658d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MeanSquaredError.evaluate() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[855], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m optimized_ann\u001b[38;5;241m.\u001b[39mforwardPropagation(X_test_scaled)  \u001b[38;5;66;03m#x_test_scaled is the scaled test data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# calculate the loss on the test set\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: MeanSquaredError.evaluate() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "# make predictions on the test set\n",
    "y_test_pred = optimized_ann.forwardPropagation(X_test_scaled)  #x_test_scaled is the scaled test data\n",
    "\n",
    "# calculate the loss on the test set\n",
    "test_loss = loss_function.evaluate(y_test_pred, y_test, y_train)\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8dfad-0bdf-4c88-9c89-c8433991b135",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100  # Set this to the number of epochs you want\n",
    "for epoch in range(epochs):\n",
    "    y_train_pred = optimized_ann.forwardPropagation(X_train_scaled)\n",
    "    \n",
    "    loss_function = MeanSquaredError()\n",
    "    training_loss = loss_function.evaluate(y_train_pred, y_train)\n",
    "\n",
    "    # Print the training loss\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Training Loss: {training_loss}\")\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_test_pred = optimized_ann.forwardPropagation(X_test_scaled)\n",
    "    test_loss = loss_function.evaluate(y_test_pred, y_test)\n",
    "\n",
    "    # Print the test loss\n",
    "    print(f\"Test Loss: {test_loss}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
